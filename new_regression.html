<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2024-12-04" />

<title>Regression Analysis</title>

<script src="site_libs/header-attrs-2.28/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="data.html">Data</a>
</li>
<li>
  <a href="eda.html">EDA</a>
</li>
<li>
  <a href="new_regression.html">Regression</a>
</li>
<li>
  <a href="report.html">Report</a>
</li>
<li>
  <a href="https://suzywwl.shinyapps.io/muisc/">Shiny App</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Regression Analysis</h1>
<h4 class="date">2024-12-04</h4>

</div>


<style>
  body {
    background-color: #F4F6ED;
    color: #191414;
    font-family: 'Lato', sans-serif; 
  }

  h1, h2, h3 {
    color: #1DB954; 
    font-weight: bold;
  }

  p {
    line-height: 1.8; 
    font-size: 1.1em;
  }

  .section {
    background-color: white;
    border-radius: 10px; 
    padding: 20px; 
    margin: 20px auto; 
    max-width: 900px; 
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
  }
</style>
<pre class="r"><code>spotify_data &lt;- 
  spotify_df %&gt;% 
  distinct(track_id,.keep_all = T) %&gt;% 
  dplyr::select(-track_id,-track_album_id,-playlist_id) %&gt;%
  mutate(track_album_release_year = as.numeric(str_sub(track_album_release_date,1,4))) %&gt;% 
  dplyr::select(-track_album_release_date) %&gt;% 
  mutate(playlist_name = factor(playlist_name),
         playlist_genre = factor(playlist_genre),
         playlist_subgenre = factor(playlist_subgenre)) %&gt;% 
  mutate(danceability = danceability * 100,
         energy = energy * 100) %&gt;% 
  mutate(key = factor(case_match(key,0 ~ &quot;C&quot;,
                          1 ~ &quot;C#/Db&quot;, 2 ~ &quot;D&quot;,
                          3 ~ &quot;D#/Eb&quot;, 4 ~ &quot;E&quot;,
                          5 ~ &quot;F&quot;, 6 ~ &quot;F#/Gb&quot;,
                          7 ~ &quot;G&quot;, 8 ~ &quot;G#/Ab&quot;,
                          9 ~ &quot;A&quot;, 10 ~ &quot;A#/Bb&quot;,
                          11 ~ &quot;B&quot;)),
         mode = factor(case_match(mode, 0 ~ &quot;minor&quot;,
                          1 ~ &quot;Major&quot;)),
         speechiness = factor(case_when(speechiness &lt; 0.33 ~ &quot;non-speech-like music&quot;,
                                 speechiness &gt;= 0.33 &amp; speechiness &lt;= 0.66 ~ &quot;mix of speech and music&quot;,
                                 speechiness &gt; 0.66 ~ &quot;entirely of spoken words&quot;)))

spotify_enhanced = 
  spotify_data |&gt; mutate(
    song_age = 2024 - track_album_release_year
  ) 

train_data &lt;- sample_frac(spotify_enhanced, size = .8)
test_data &lt;- anti_join(spotify_enhanced, train_data, by = &quot;track_name&quot;)
train_data_no_0 &lt;-train_data |&gt; filter(track_popularity &gt; 0)</code></pre>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<div id="despcription" class="section level3">
<h3>Despcription</h3>
<p>This analysis explores the relationship between the
<strong>popularity of a song</strong> (outcome variable) and its
attributes (predictors). The analysis is divided into two parts:</p>
<ol style="list-style-type: decimal">
<li><strong>Identifying Key Predictors</strong>: Using multiple linear
regression and random forest models to explore significant predictors of
song popularity.</li>
<li><strong>Exploring Transformations and Simplification</strong>:
Evaluating the effect of variable transformations on prediction power
and testing Lasso regression for model simplification.</li>
</ol>
<p>The following preprocessing steps were applied to the dataset:</p>
<ul>
<li><strong>Column Removal</strong>:
<ul>
<li>Removed unnecessary columns: <code>track_id</code>,
<code>track_album_id</code>, and <code>playlist_id</code>.</li>
</ul></li>
<li><strong>Date Transformation</strong>:
<ul>
<li>Converted <code>track_album_release_date</code> to
<code>track_album_release_year</code>.</li>
<li>Calculated <code>song_age</code> as 2024 -
<code>track_album_release_year</code>.</li>
</ul></li>
<li><strong>Categorical Conversion</strong>:
<ul>
<li>Converted columns to factors: <code>playlist_name</code>,
<code>playlist_genre</code>, <code>playlist_subgenre</code>,
<code>key</code>, <code>mode</code>, and <code>speechiness</code>
(categorized based on value).</li>
</ul></li>
<li><strong>Scaling and Adjustments</strong>:
<ul>
<li>Multiplied <code>danceability</code> and <code>energy</code> by
100.</li>
</ul></li>
<li><strong>Data Splitting</strong>:
<ul>
<li>Split the dataset into training and testing sets for model
evaluation.</li>
</ul></li>
</ul>
<pre class="r"><code># type of parameters
t(t(map(spotify_enhanced, class)))</code></pre>
<pre><code>##                          [,1]       
## track_name               &quot;character&quot;
## track_artist             &quot;character&quot;
## track_popularity         &quot;numeric&quot;  
## track_album_name         &quot;character&quot;
## playlist_name            &quot;factor&quot;   
## playlist_genre           &quot;factor&quot;   
## playlist_subgenre        &quot;factor&quot;   
## danceability             &quot;numeric&quot;  
## energy                   &quot;numeric&quot;  
## key                      &quot;factor&quot;   
## loudness                 &quot;numeric&quot;  
## mode                     &quot;factor&quot;   
## speechiness              &quot;factor&quot;   
## acousticness             &quot;numeric&quot;  
## instrumentalness         &quot;numeric&quot;  
## liveness                 &quot;numeric&quot;  
## valence                  &quot;numeric&quot;  
## tempo                    &quot;numeric&quot;  
## duration_ms              &quot;numeric&quot;  
## track_album_release_year &quot;numeric&quot;  
## song_age                 &quot;numeric&quot;</code></pre>
<pre class="r"><code># Check the correlation between numeric parameters.  help detect hidden patterns among variables
numeric_vars &lt;- spotify_data %&gt;% 
  dplyr::select(track_popularity, danceability, energy, loudness, 
         acousticness, instrumentalness, liveness, valence, 
         tempo, duration_ms, track_album_release_year)

correlation_matrix &lt;- cor(numeric_vars)
corrplot(correlation_matrix, method = &quot;color&quot;, type = &quot;upper&quot;,
         tl.col = &quot;black&quot;, tl.srt = 45)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>From the correlation plot of the numeric variables, we observed:</p>
<ul>
<li><strong>Energy and Loudness</strong>: These two variables are highly
correlated. This is expected, as loudness is a measure of the energy of
a song.</li>
<li><strong>Energy and Acoustics</strong>: These variables are highly
negatively correlated, which is also expected.</li>
</ul>
<p>The correlation plot helps us identify hidden patterns among
variables and guides the feature selection process.</p>
<pre class="r"><code># Music popularity often follows a &quot;power law&quot; distribution
# Few very popular songs, many less popular ones
spotify_data %&gt;%
  arrange(desc(track_popularity)) %&gt;%
  mutate(rank = row_number()) %&gt;%
  ggplot(aes(x = rank, y = track_popularity)) +
  geom_line() +
  labs(title = &quot;Popularity Distribution&quot;)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Then we try to do the distribution plot to detect the distribution of
popularity. From the plot, we can see that the popularity of songs
follows a “power law” distribution. This means that there are a few very
popular songs and many less popular ones. This is a common distribution
for popularity data, as it is often the case that a few songs become
very popular while most songs remain relatively unknown.</p>
</div>
<div id="distribution-of-dataset" class="section level3">
<h3>Distribution of dataset</h3>
<pre class="r"><code>p1 &lt;- ggplot(train_data, aes(x = track_popularity)) +
  geom_histogram(binwidth = 1, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Original Distribution&quot;, x = &quot;Track Popularity&quot;, y = &quot;Count&quot;) +
  theme_minimal()
p1</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-5-1.png" width="672" />
The distribution of track popularity shows:</p>
<ul>
<li><strong>High Frequency at Zero Popularity</strong>: A significant
number of songs have a popularity score of zero, representing tracks
that are rarely or never played, newly added songs with no audience, or
niche tracks with limited reach.</li>
<li><strong>Broad Range for Other Popularity Scores</strong>: Beyond
zero, the distribution is relatively uniform, with a slight bell-shaped
curve centered around the middle of the popularity scale (around 50).
This suggests many songs have moderate popularity, while fewer achieve
very high scores.</li>
<li><strong>Tapering at Higher Scores</strong>: The declining bars for
scores above 70 indicate that only a small proportion of tracks reach
the highest levels of popularity.</li>
</ul>
<p>This distribution highlights the need for possible transformations to
address the over representation at zero.</p>
</div>
</div>
<div id="statistical-inference-about-result" class="section level2">
<h2>Statistical Inference About Result</h2>
<div id="multiple-linear-regression" class="section level3">
<h3>Multiple Linear Regression</h3>
<pre class="r"><code>set.seed(123)
model_all_input &lt;-
  lm(track_popularity ~ danceability + energy + loudness + acousticness + instrumentalness + valence +
       tempo + liveness + duration_ms + speechiness + song_age + playlist_genre + key + mode, 
     data = train_data)

summary(model_all_input) |&gt;
  broom::tidy() |&gt;
  knitr::kable(digits = 3)</code></pre>
<table>
<colgroup>
<col width="48%" />
<col width="12%" />
<col width="13%" />
<col width="13%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">50.250</td>
<td align="right">5.176</td>
<td align="right">9.709</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">danceability</td>
<td align="right">0.094</td>
<td align="right">0.013</td>
<td align="right">7.224</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">energy</td>
<td align="right">-0.219</td>
<td align="right">0.014</td>
<td align="right">-15.724</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">loudness</td>
<td align="right">1.193</td>
<td align="right">0.076</td>
<td align="right">15.782</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">acousticness</td>
<td align="right">3.955</td>
<td align="right">0.831</td>
<td align="right">4.758</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">instrumentalness</td>
<td align="right">-6.359</td>
<td align="right">0.721</td>
<td align="right">-8.820</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">valence</td>
<td align="right">-1.223</td>
<td align="right">0.779</td>
<td align="right">-1.570</td>
<td align="right">0.116</td>
</tr>
<tr class="even">
<td align="left">tempo</td>
<td align="right">0.028</td>
<td align="right">0.006</td>
<td align="right">4.829</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">liveness</td>
<td align="right">-2.579</td>
<td align="right">0.990</td>
<td align="right">-2.605</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">duration_ms</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">-15.453</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">speechinessmix of speech and music</td>
<td align="right">5.120</td>
<td align="right">4.786</td>
<td align="right">1.070</td>
<td align="right">0.285</td>
</tr>
<tr class="even">
<td align="left">speechinessnon-speech-like music</td>
<td align="right">6.094</td>
<td align="right">4.751</td>
<td align="right">1.283</td>
<td align="right">0.200</td>
</tr>
<tr class="odd">
<td align="left">song_age</td>
<td align="right">-0.008</td>
<td align="right">0.018</td>
<td align="right">-0.428</td>
<td align="right">0.669</td>
</tr>
<tr class="even">
<td align="left">playlist_genrelatin</td>
<td align="right">7.589</td>
<td align="right">0.586</td>
<td align="right">12.961</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">playlist_genrepop</td>
<td align="right">12.237</td>
<td align="right">0.547</td>
<td align="right">22.371</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">playlist_genrer&amp;b</td>
<td align="right">2.535</td>
<td align="right">0.613</td>
<td align="right">4.134</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">playlist_genrerap</td>
<td align="right">7.439</td>
<td align="right">0.556</td>
<td align="right">13.379</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">playlist_genrerock</td>
<td align="right">11.093</td>
<td align="right">0.659</td>
<td align="right">16.836</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">keyA#/Bb</td>
<td align="right">0.579</td>
<td align="right">0.762</td>
<td align="right">0.759</td>
<td align="right">0.448</td>
</tr>
<tr class="even">
<td align="left">keyB</td>
<td align="right">0.726</td>
<td align="right">0.707</td>
<td align="right">1.027</td>
<td align="right">0.305</td>
</tr>
<tr class="odd">
<td align="left">keyC</td>
<td align="right">0.986</td>
<td align="right">0.682</td>
<td align="right">1.445</td>
<td align="right">0.148</td>
</tr>
<tr class="even">
<td align="left">keyC#/Db</td>
<td align="right">0.741</td>
<td align="right">0.664</td>
<td align="right">1.115</td>
<td align="right">0.265</td>
</tr>
<tr class="odd">
<td align="left">keyD</td>
<td align="right">-0.134</td>
<td align="right">0.718</td>
<td align="right">-0.187</td>
<td align="right">0.851</td>
</tr>
<tr class="even">
<td align="left">keyD#/Eb</td>
<td align="right">-0.371</td>
<td align="right">1.035</td>
<td align="right">-0.358</td>
<td align="right">0.720</td>
</tr>
<tr class="odd">
<td align="left">keyE</td>
<td align="right">-0.230</td>
<td align="right">0.762</td>
<td align="right">-0.302</td>
<td align="right">0.763</td>
</tr>
<tr class="even">
<td align="left">keyF</td>
<td align="right">1.299</td>
<td align="right">0.725</td>
<td align="right">1.793</td>
<td align="right">0.073</td>
</tr>
<tr class="odd">
<td align="left">keyF#/Gb</td>
<td align="right">0.966</td>
<td align="right">0.732</td>
<td align="right">1.320</td>
<td align="right">0.187</td>
</tr>
<tr class="even">
<td align="left">keyG</td>
<td align="right">-0.361</td>
<td align="right">0.684</td>
<td align="right">-0.529</td>
<td align="right">0.597</td>
</tr>
<tr class="odd">
<td align="left">keyG#/Ab</td>
<td align="right">1.758</td>
<td align="right">0.749</td>
<td align="right">2.348</td>
<td align="right">0.019</td>
</tr>
<tr class="even">
<td align="left">modeminor</td>
<td align="right">-0.384</td>
<td align="right">0.323</td>
<td align="right">-1.192</td>
<td align="right">0.233</td>
</tr>
</tbody>
</table>
<p>Above is the result of multiple linear regression, the model didn’t
include the sub_genre as it is hard to define the sub-genre of a song
and there might be some error. Also to avoid the complexity. For this
part, the model would only use genre but not the sub-genre.</p>
<p>The regression results revealed several significant predictors:</p>
<ul>
<li><p><strong>Danceability</strong>: Positive and highly significant
(<span class="math inline">\(\beta = 0.096\)</span>, p &lt; 0.001). Each
unit increase in danceability is associated with a 0.096 increase in
popularity.</p></li>
<li><p><strong>Energy</strong>: Negative and highly significant (<span
class="math inline">\(\beta = -0.222\)</span>, p &lt; 0.001), indicating
that each unit increase in energy is associated with a 0.222 decrease in
popularity.</p></li>
<li><p><strong>Loudness</strong>: Positive and highly significant (<span
class="math inline">\(\beta = 1.268\)</span>, p &lt; 0.001), showing
that louder tracks tend to be more popular.</p></li>
<li><p><strong>Acousticness</strong>: Positive and highly significant
(<span class="math inline">\(\beta = 4.503\)</span>, p &lt; 0.001),
demonstrating that more acoustic tracks tend to have higher
popularity.</p></li>
<li><p><strong>Instrumentalness</strong>: Negative and highly
significant (<span class="math inline">\(\beta = -5.935\)</span>, p &lt;
0.001), implying that instrumental tracks tend to be less
popular.</p></li>
<li><p><strong>Valence</strong>: Negative and significant (<span
class="math inline">\(\beta = -1.793\)</span>, p = 0.021), showing that
tracks with lower valence (less “happy”) tend to be more
popular.</p></li>
<li><p><strong>Tempo</strong>: Positive and highly significant (<span
class="math inline">\(\beta = 0.028\)</span>, p &lt; 0.001), suggesting
faster tracks are slightly more popular.</p></li>
<li><p><strong>Liveness</strong>: Negative and significant (<span
class="math inline">\(\beta = -3.261\)</span>, p = 0.001), indicating
that tracks with less “live” characteristics tend to be more
popular.</p></li>
<li><p><strong>Duration_ms</strong>: Negative and highly significant
(<span class="math inline">\(\beta = 0.000\)</span>, p &lt; 0.001),
showing that shorter tracks tend to be more popular.</p></li>
<li><p><strong>Playlist Genre</strong> (compared to EDM): All genres
show significant positive effects:</p>
<ul>
<li>Pop has the strongest effect (<span class="math inline">\(\beta =
12.402\)</span>, p &lt; 0.001)</li>
<li>Rock shows a large positive effect (<span
class="math inline">\(\beta = 11.328\)</span>, p &lt; 0.001)</li>
<li>Latin and Rap show moderate effects (<span
class="math inline">\(\beta = 7.518\)</span> and <span
class="math inline">\(\beta = 7.330\)</span> respectively, p &lt;
0.001)</li>
<li>R&amp;B has a smaller but significant effect (<span
class="math inline">\(\beta = 2.739\)</span>, p &lt; 0.001)</li>
</ul></li>
<li><p><strong>Key</strong> (compared to Key A): Most keys don’t show
significant differences, except:</p>
<ul>
<li>G#/Ab shows a significant positive effect (<span
class="math inline">\(\beta = 2.340\)</span>, p = 0.002)</li>
<li>C is marginally significant (<span class="math inline">\(\beta =
1.334\)</span>, p = 0.050)</li>
</ul></li>
<li><p><strong>Mode</strong> (compared to Major): The minor mode shows
no significant difference (<span class="math inline">\(\beta =
-0.421\)</span>, p = 0.190)</p></li>
</ul>
<p>Notably, speechiness (both mix and non-speech-like) and song age
showed no significant effects on popularity (p &gt; 0.05).</p>
<pre class="r"><code>par(mfrow = c(2,2))
plot(model_all_input)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-7-1.png" width="672" />
1. <strong>Residuals vs Fitted Plot</strong> (top left): - From this
plot, we observe: - A fairly random scatter around the horizontal line
at y=0 - A slight fan shape, with residuals spreading out more at higher
fitted values - This suggests some minor violation of the
homoscedasticity assumption, meaning the variance of residuals isn’t
completely constant</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Q-Q (Quantile-Quantile) Plot</strong> (top right):</li>
</ol>
<ul>
<li>Tests the <strong>normality</strong> assumption of residuals</li>
<li>In this plot:
<ul>
<li>Points generally follow the diagonal line</li>
<li>Some deviation at the tails, particularly at both ends</li>
<li>This indicates that the residuals are approximately normally
distributed, but with slightly heavier tails than a perfect normal
distribution</li>
</ul></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Scale-Location Plot</strong> (bottom left):</li>
</ol>
<ul>
<li>Test for <strong>homoscedasticity</strong></li>
<li>Shows the square root of standardized residuals vs fitted
values</li>
<li>In this case:
<ul>
<li>The red line is slightly trending upward</li>
<li>The spread of points increases somewhat with fitted values</li>
<li>This reinforces what we saw in the Residuals vs Fitted plot: there’s
some heteroscedasticity present</li>
</ul></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li><strong>Residuals vs Leverage Plot</strong> (bottom right):</li>
</ol>
<ul>
<li>From this plot:
<ul>
<li>Most points fall within acceptable bounds</li>
<li>There are some observations with higher leverage (on the right)</li>
<li>A few points are outside Cook’s distance lines, suggesting they
might be influential observations</li>
</ul></li>
</ul>
<p><strong>Overall Assessment</strong>:</p>
<p>The model generally meets the assumptions of linear regression, but
with some minor violations: - The main concern is some
heteroscedasticity in the residuals - The normality assumption is
reasonably met - There are a few potentially influential observations
that might warrant further investigation</p>
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<p>Given the linear models are only capture the linear relationship
between the predictors and the popularity, we also try to use the random
forest to see if the non-linear relationship could be captured. Also,
random forest model was employed to identify the most influential
predictors of song popularity.</p>
<pre class="r"><code>rf_model &lt;- randomForest(
    track_popularity ~ danceability + energy + loudness + 
                      acousticness + instrumentalness + liveness + 
                      valence + tempo + duration_ms + track_album_release_year +
                      playlist_genre,
    data = train_data,
    ntree = 100,     
    importance = TRUE
)

# 3. Check model performance
rf_predictions &lt;- predict(rf_model, test_data)

rf_rmse &lt;- sqrt(mean((test_data$track_popularity - rf_predictions)^2))
print(paste(&quot;Random Forest RMSE:&quot;, rf_rmse))

# 4. Variable Importance
varImpPlot(rf_model, 
           main = &quot;Variable Importance Plot&quot;)

# Print importance scores
importance(rf_model)

# 5. Tune hyperparameters
ctrl &lt;- trainControl(
    method = &quot;cv&quot;,
    number = 3,
    verboseIter = TRUE
)

tuning_grid &lt;- expand.grid(
    mtry = seq(2, 6, by = 2)  # Number of variables to try at each split
)

rf_tuned &lt;- train(
    track_popularity ~ danceability + energy + loudness + 
                      acousticness + instrumentalness + liveness + 
                      valence + tempo + duration_ms + track_album_release_year +
                      playlist_genre,
    data = train_data,
    method = &quot;rf&quot;,
    tuneGrid = tuning_grid,
    trControl = ctrl
)

print(rf_tuned$bestTune)

# 6. Final model with best parameters
final_rf &lt;- randomForest(
    track_popularity ~ danceability + energy + loudness + 
                      acousticness + instrumentalness + liveness + 
                      valence + tempo + duration_ms + track_album_release_year +
                      playlist_genre,
    data = train_data,
    ntree = 100,
    mtry = rf_tuned$bestTune$mtry
)

# 7. Compare with original linear model
final_rf_predictions &lt;- predict(final_rf, test_data)
rf_rmse &lt;- sqrt(mean((test_data$track_popularity - final_rf_predictions)^2))

plot_data &lt;- data.frame(
    Actual = test_data$track_popularity,
    Predicted = final_rf_predictions
)

ggplot(plot_data, aes(x = Actual, y = Predicted)) +
    geom_point(alpha = 0.3) +
    geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) +
    labs(title = &quot;Random Forest: Actual vs Predicted Values&quot;,
         x = &quot;Actual Popularity&quot;,
         y = &quot;Predicted Popularity&quot;) +
    theme_minimal()

# 8. Feature importance visualization
importance_df &lt;- data.frame(
    Feature = rownames(importance(final_rf)),
    Importance = importance(final_rf)[,1]
) %&gt;%
    arrange(desc(Importance))

ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
    geom_bar(stat = &quot;identity&quot;) +
    coord_flip() +
    theme_minimal() +
    labs(title = &quot;Feature Importance in Random Forest Model&quot;,
         x = &quot;Features&quot;,
         y = &quot;Importance Score&quot;)</code></pre>
<p>The random forest model identified the following key features
influencing song popularity:</p>
<ul>
<li><strong>Track Album Release Year</strong>: The most significant
predictor, suggesting that newer songs may tend to have higher
popularity scores.</li>
<li><strong>Duration (ms)</strong>: Indicates that song length might
play a role in popularity.</li>
<li><strong>Loudness and Energy</strong>: These features, which are
highly correlated, both significantly contribute to a track’s
appeal.</li>
<li><strong>Acousticness</strong>: A strong negative relationship with
energy, influencing popularity depending on the type of song.</li>
<li><strong>Tempo and Danceability</strong>: Contribute to the rhythmic
and dynamic feel of the track, impacting its popularity.</li>
<li><strong>Other Factors</strong>: Valence, liveness, instrumentalness,
and playlist genre were also important but to a lesser extent.</li>
</ul>
</div>
</div>
<div id="exploring-transformations-and-simplification"
class="section level2">
<h2>Exploring Transformations and Simplification</h2>
<p>To improve predictive power and address potential heteroscedasticity,
several methods were applied to transform the
<code>track popularity</code> variable. These included:</p>
<ul>
<li><strong>Log Transformation</strong>: Reduces skewness and helps
stabilize variance for heavily skewed data.</li>
<li><strong>Square Root Transformation</strong>: Useful for moderate
skewness, providing a balanced transformation.</li>
<li><strong>Box-Cox Transformation</strong>: Applies a parameterized
transformation to optimize normality and homoscedasticity.</li>
</ul>
<p>These transformations were evaluated to determine their effect on the
predictive accuracy and the overall model performance.</p>
<div id="distribution-transformation" class="section level3">
<h3>Distribution Transformation</h3>
<pre class="r"><code># Log transformation
model_log &lt;- lm(log1p(track_popularity) ~ danceability + energy + loudness + 
                acousticness + instrumentalness + liveness + 
                valence + tempo + duration_ms + song_age,
                data = train_data)

# Square root transformation
model_sqrt &lt;- lm(sqrt(track_popularity) ~ danceability + energy + loudness + 
                 acousticness + instrumentalness + liveness + 
                 valence + tempo + duration_ms + song_age,
                 data = train_data)
shifted_popularity &lt;- train_data$track_popularity + 1  # Add 1 to handle zeros

# Box-Cox transformation
bc &lt;- boxcox(shifted_popularity ~ danceability + energy + loudness + 
             acousticness + instrumentalness + liveness + 
             valence + tempo + duration_ms + song_age,
             data = train_data)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code># Find optimal lambda
lambda &lt;- bc$x[which.max(bc$y)]

# Apply Box-Cox transformation
model_boxcox &lt;- lm((track_popularity^lambda - 1)/lambda ~ danceability + energy + 
                   loudness + acousticness + instrumentalness + liveness + 
                   valence + tempo + duration_ms + song_age,
                   data = train_data)</code></pre>
<p>The Lambda is close to 1, which means the original model might be
better. But we still need to check the distribution after
transformation.</p>
<pre class="r"><code>p1 &lt;- ggplot(train_data, aes(x = track_popularity)) +
  geom_histogram(binwidth = 1, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Original Distribution&quot;, x = &quot;Track Popularity&quot;, y = &quot;Count&quot;) +
  theme_minimal()


## popularity score could be 0
p2 &lt;- ggplot(train_data, aes(x = log1p(track_popularity))) +
  geom_histogram(binwidth = 0.1, fill = &quot;lightgreen&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Log Transformation&quot;, x = &quot;Log(Track Popularity + 1)&quot;, y = &quot;Count&quot;) +
  theme_minimal()


p3 &lt;- ggplot(train_data, aes(x = sqrt(track_popularity))) +
  geom_histogram(binwidth = 0.5, fill = &quot;salmon&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Square Root Transformation&quot;, x = &quot;Sqrt(Track Popularity)&quot;, y = &quot;Count&quot;) +
  theme_minimal()

p4 &lt;- ggplot(train_data, aes(x = (track_popularity^lambda - 1)/lambda)) +
  geom_histogram(binwidth = 1, fill = &quot;purple&quot;, color = &quot;black&quot;) +
  labs(title = &quot;Box-Cox Transformation&quot;, x = &quot;Box-Cox Transformed Popularity&quot;, y = &quot;Count&quot;) +
  theme_minimal()

grid.arrange(p1, p2, p3, p4, ncol = 2)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-10-1.png" width="672" />
The distribution of the transformed popularity scores shows that they
all looks normal besides the concentration of score of 0 in
popularity.</p>
<pre class="r"><code>check_residuals &lt;- function(model) {
    par(mfrow = c(2,2))
    plot(model)
}

check_residuals(model_log)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>check_residuals(model_sqrt)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<pre class="r"><code>check_residuals(model_boxcox)</code></pre>
<p><img src="new_regression_files/figure-html/unnamed-chunk-11-3.png" width="672" />
Other than the original model, the Box-Cox transformation model has the
best distribution of residuals. Then we also compare the RMSE of the
models to see which model is better. The log and square root
transformation seems obey the linearity and normality assumption.
Couldn’t tell which one is better in terms of prediction power, so then
we compare the RMSE of the models.</p>
<pre class="r"><code>compare_models &lt;- function(models, test_data) {
    results &lt;- sapply(models, function(model) {
        pred &lt;- predict(model, newdata = test_data)
        rmse &lt;- sqrt(mean((test_data$track_popularity - pred)^2))
        return(rmse)
    })
    return(results)
}

models_list = 
  list(
    &quot;all_parameter_model&quot; = model_all_input,
    &quot;log&quot; = model_log, 
    &quot;sqrt&quot; = model_sqrt,
    &quot;box&quot; = model_boxcox
)
results &lt;- compare_models(models_list, test_data)
results</code></pre>
<pre><code>## all_parameter_model                 log                sqrt                 box 
##            21.78195            43.14219            41.03919            29.56895</code></pre>
<p>Actually, based on RMSE, the original as the lowest RMSE. So we would
keep the original model.</p>
</div>
<div id="lasso-regression" class="section level3">
<h3>Lasso Regression</h3>
<pre class="r"><code>spotify_data_filtered &lt;- spotify_data %&gt;% filter(track_popularity &gt; 0)
spotify_data_matrix &lt;- model.matrix(
  track_popularity ~ 
    danceability + energy + loudness + instrumentalness + valence + tempo + duration_ms +
    track_album_release_year + playlist_genre + playlist_subgenre + key + mode, data = spotify_data_filtered)[, -1]

y &lt;- spotify_data_filtered$track_popularity

set.seed(123)
train_indices &lt;- sample(1:nrow(spotify_data_matrix), size = 0.7 * nrow(spotify_data_matrix))
train_x &lt;- spotify_data_matrix[train_indices, ]
test_x &lt;- spotify_data_matrix[-train_indices, ]
train_y &lt;- y[train_indices]
test_y &lt;- y[-train_indices]

# Apply Lasso regression (alpha = 1)
lasso_model &lt;- cv.glmnet(train_x, train_y, alpha = 1)

# Get best lambda 
best_lambda_lasso &lt;- lasso_model$lambda.min
print(paste(&quot;Best lambda for Lasso:&quot;, best_lambda_lasso))</code></pre>
<pre><code>## [1] &quot;Best lambda for Lasso: 0.0449121893403259&quot;</code></pre>
<pre class="r"><code># Predict on test set using Lasso model
lasso_predictions &lt;- predict(lasso_model, s = best_lambda_lasso, newx = test_x)

# Calculate RMSE for Lasso
lasso_rmse &lt;- sqrt(mean((test_y - lasso_predictions)^2))
print(paste(&quot;Lasso RMSE:&quot;, lasso_rmse))</code></pre>
<pre><code>## [1] &quot;Lasso RMSE: 19.6148349477214&quot;</code></pre>
<pre class="r"><code># Get coefficients at best lambda
lasso_coef &lt;- coef(lasso_model, s = best_lambda_lasso)

lasso_coef_df &lt;- data.frame(
  feature = rownames(lasso_coef),
  coefficient = as.vector(lasso_coef)
) %&gt;%
  arrange(desc(abs(coefficient)))

lasso_coef_df %&gt;%
  filter(coefficient == 0) </code></pre>
<pre><code>##              feature coefficient
## 1  playlist_genrer&amp;b           0
## 2  playlist_genrerap           0
## 3 playlist_genrerock           0
## 4               keyD           0
## 5           keyD#/Eb           0</code></pre>
<p><strong>Interpretation</strong>: In Lasso regression, the best lambda
is 0.004, the RMSE is 19.6, and the Beta of above 5 variables are
eliminated.</p>
<ul>
<li>These variables are considered less important for predicting track
popularity</li>
<li>Their effects might be:
<ul>
<li>Truly negligible</li>
<li>Captured by other correlated variables</li>
<li>Redundant in the presence of other predictors</li>
</ul></li>
</ul>
<p><a href="index.html">Back to Home</a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
